<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> llm questionnaire processing | C. Rydalch </title> <meta name="author" content="C. Rydalch"> <meta name="description" content="tool to generate accurate responses to customer security questionnaires using an LLM"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%98&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://rydalch.net/projects/llm-answers/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "llm questionnaire processing",
            "description": "tool to generate accurate responses to customer security questionnaires using an LLM",
            "published": "November 14, 2025",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">C.</span> Rydalch </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>llm questionnaire processing</h1> <p>tool to generate accurate responses to customer security questionnaires using an LLM</p> </d-title> <d-article> <h3 id="from-naive-rag-to-a-file-navigating-agent-a-journey-in-automating-security-questionnaires"><strong>From Naive RAG to a File-Navigating Agent: A Journey in Automating Security Questionnaires</strong></h3> <p>One of the most time consuming activities for many organizations with business customers is responding to inquiries about security practices. Most customers have a questionnaire they want completed to help them evaluated how well the company meets their requirements. Completing the questionnaire usually requires an analyst to review each question and provide a response.</p> <p>In order to provide an accurate response, the analyst needs to be someone who understands the company’s security policies and standards as well as the company’s products and services.</p> <p>An LLM seems like an ideal tool to automate the generation of responses. I created a proof of concept to have an LLM respond to questions based on a set of policies. Initially I implemented a RAG approach, which worked well for my test policy documents. When I tested a large, single policy document, it exceeded the context window for the model and the responses would get stuck on the table of contents.</p> <p>A commercial provider had a similar issue, as shown here:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/SCF-Control-Mapper-480.webp 480w,/assets/img/SCF-Control-Mapper-800.webp 800w,/assets/img/SCF-Control-Mapper-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/SCF-Control-Mapper.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Screenshot of processing a policy with over 100 pages. </div> <p>So I tried an agentic approach that led to much better and more consistent outcomes. It works with a large, single policy document with over a hundred pages, and it works with a set of smaller, 3 to 5 page each, policy documents.</p> <p>This has been a fascinating journey, moving far beyond my initial scope into the nuanced and often challenging world of building truly robust agents. I went from an initial RAG idea, through a “RAG Obituary” paradigm shift, to the local, file-navigating agent.</p> <h4 id="phase-1-the-rag-illusion"><strong>Phase 1: The RAG Illusion</strong></h4> <p>The initial idea was straightforward. The problem seemed custom-made for Retrieval-Augmented Generation (RAG), the go-to architecture for question-answering over a private knowledge base.</p> <p>The setup was simple:</p> <ol> <li> <strong>Ingest:</strong> Process all our security documents—PDFs, DOCX files, etc.—into clean text.</li> <li> <strong>Embed &amp; Store:</strong> Use a sentence-transformer model to convert text chunks into vector embeddings and store them in a ChromaDB vector database.</li> <li> <strong>Retrieve &amp; Generate:</strong> When a question came in, use similarity search to find the most relevant chunks and feed them to an LLM to synthesize an answer.</li> </ol> <p>The first results were deceptively promising. But as soon as a questionnaire used slightly different terminology (asking about “business continuity” when our policy said “resilience management”) the system failed silently. It was a black box that either worked or it didn’t, and I had little visibility into why.</p> <h4 id="phase-2-the-paradigm-shift--the-rag-obituary"><strong>Phase 2: The Paradigm Shift – The “RAG Obituary”</strong></h4> <p>The turning point came from an article I came across on Hacker News titled “<a href="https://www.nicolasbustamante.com/p/the-rag-obituary-killed-by-agents" rel="external nofollow noopener" target="_blank">The RAG Obituary: Killed by Agents, Buried by Context Windows</a>.” Around the same time, Anthropic published an article with similar takaways titled “<a href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents" rel="external nofollow noopener" target="_blank">Effective context engineering for AI agents</a>.”</p> <p>It argued that the entire RAG pipeline of chunking, embedding, and vector databases was a clever workaround for an era of small context windows. The future, it claimed, belonged to <strong>investigator agents</strong> that could navigate and read entire documents directly, much like a human would, using simple but powerful tools like <code class="language-plaintext highlighter-rouge">grep</code>.</p> <p>This was a big shift in thinking. The goal was no longer to find the most similar fragment of text but to build an agent that could investigate a file system to find the correct answer.</p> <h4 id="phase-3-building-the-investigator--an-agent-with-tools"><strong>Phase 3: Building the Investigator – An Agent with Tools</strong></h4> <p>Embracing this new philosophy meant a complete architectural overhaul:</p> <ol> <li> <strong>Goodbye, Vector Database:</strong> I scrapped ChromaDB. The knowledge base became a simple folder of clean <code class="language-plaintext highlighter-rouge">.txt</code> files.</li> <li> <strong>Hello, Command-Line Power:</strong> I created a set of Python functions that acted as the agent’s “hands,” using the <code class="language-plaintext highlighter-rouge">subprocess</code> module to call <code class="language-plaintext highlighter-rouge">grep</code>. The primary tools were: <ul> <li> <code class="language-plaintext highlighter-rouge">search_content</code>: Searches the entire content of all files for keywords and returns the names of the files that contain them.</li> <li> <code class="language-plaintext highlighter-rouge">read_file</code>: Reads the beginning of a document, perfect for grabbing a Table of Contents.</li> <li> <code class="language-plaintext highlighter-rouge">go_to_section</code>: A navigation tool to jump directly to a specific section ID (e.g., “AC-12”) within a large document.</li> </ul> </li> <li> <strong>The Agent Core:</strong> Using LangChain, I built a “ReAct” (Reason-Act) loop. The agent was given a persona and a core directive: analyze the question, choose a tool, execute it, observe the result, and repeat until you have the answer.</li> </ol> <p>This was no longer a static pipeline; it was a dynamic, thinking process.</p> <h4 id="phase-4-the-gauntlet--where-the-real-learning-happened"><strong>Phase 4: The Gauntlet – Where the Real Learning Happened</strong></h4> <p>Theory is one thing; practice is another. Making the agent work reliably, especially with local open-source models, was a challenge.</p> <p><strong>Lesson 1: The Hallucination Menace</strong> The first major failure came when the agent was asked for a “public privacy policy link” as one of the test questions in the security questionnaire. It ignored the documents entirely and confidently provided the URL to its own creator’s (xAI’s) privacy policy. It “broke character.”</p> <ul> <li> <strong>The Fix:</strong> A much stricter prompt persona. We had to explicitly command it: <strong>“You are a factual Q&amp;A assistant. Your <em>only</em> source of knowledge is the set of tools you have been given. You must not use any external knowledge. Do not make up information or filenames.”</strong> This constraint was crucial to keeping it grounded.</li> </ul> <p><strong>Lesson 2: The Monolithic Document Trap</strong> When I tested the agent against a single, 300-page security manual, it failed consistently. It would correctly use <code class="language-plaintext highlighter-rouge">read_file</code> to see the Table of Contents, find the perfect section title on page 150, but the navigation tool was too simplistic. It would get stuck in the long Table of Contents, never reaching the actual content deep within the document.</p> <ul> <li> <strong>The Fix:</strong> A smarter tool. The tool was rewritten to not just stop the first time it found a match for a string, but to find all matches within the document (and a few lines before and after) and then intelligently extract a complete answer.</li> </ul> <p><strong>Lesson 3: The Local Model Dilemma</strong> While commercial models like GPT-4 followed the turn-by-turn logic well, local models like Llama 3.1 Instruct and Hermes 7B struggled. They would often “hallucinate” an entire multi-step investigation in a single turn, inventing fake tool outputs and presenting a final answer without ever actually using the tools. They were trying to solve the whole problem in one go.</p> <ul> <li> <strong>The Fix:</strong> Radical prompt simplification. The elegant, multi-part strategy in the prompt was confusing the model. We had to replace it with a blunt, rigid set of rules: <strong>“You must only call ONE tool per step. Do not plan multiple steps ahead.”</strong> This reduced the model’s “creative freedom” and forced it into the step-by-step reasoning loop we needed.</li> </ul> <h4 id="phase-5-the-final-architecture--a-model-agnostic-investigator"><strong>Phase 5: The Final Architecture – A Model-Agnostic Investigator</strong></h4> <p>The final system is a testament to this iterative journey. It is:</p> <ol> <li> <strong>Agentic, Not RAG-based:</strong> It doesn’t rely on semantic similarity. It performs a true investigation by discovering, navigating, and reading documents.</li> <li> <strong>Flexible and Adaptable:</strong> The prompt now teaches a universal strategy. The agent starts by discovering files. If it finds many specific policy documents, it reads them. If it finds one large manual, it switches to the TOC-navigation strategy. It adapts to its environment.</li> <li> <strong>Model-Agnostic:</strong> By using LangChain’s core tool-calling abstractions, the agent is no longer tied to a specific model’s output format. I can swap between a local Llama 3 model and a commercial API like Claude 3 by changing a single line in a config file.</li> <li> <strong>Fast and Efficient:</strong> Using <code class="language-plaintext highlighter-rouge">grep</code> for file searching is orders of magnitude faster than loading, chunking, and embedding files. The entire process for answering a question now takes seconds, not minutes.</li> </ol> <h4 id="the-takeaway-build-your-agents-brain-and-body-together"><strong>The Takeaway: Build Your Agent’s Brain and Body Together</strong></h4> <p>This project drove home a core lesson of the post-RAG era: an agent’s intelligence is not just in the LLM. It’s in the co-design of its “brain” (the prompt and strategy) and its “body” (the tools it has to work with). The initial hallucination problems weren’t solved by a better model, but by a better prompt. The navigation problems weren’t solved by a better prompt, but by a better tool.</p> <p>Moving from a simple pipeline to this robust investigator was a shift from asking “Can an LLM answer this?” to “How can I build a reliable, verifiable process where an LLM is a constrained and supervised component?” The result is a system that feels less like magic and works more like a tireless, highly competent junior analyst.</p> <hr> <p>The complete code is available on my GitHub, including setup instructions: <a href="https://github.com/rydalch/security-questionnaire-agent" rel="external nofollow noopener" target="_blank">https://github.com/rydalch/security-questionnaire-agent</a></p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <d-article> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 C. Rydalch. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>